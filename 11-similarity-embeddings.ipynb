{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "SÃ¤tze extrahiert aus der UN-Generaldebatte 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# File name and URL\n",
    "file_name = \"sentences.txt\"\n",
    "url = \"https://github.com/datanizing/m3-llm-workshop/raw/main/sentences.txt\"\n",
    "\n",
    "# Check if the file exists, if not, download it\n",
    "if not os.path.isfile(file_name):\n",
    "    print(f\"{file_name} does not exist. Downloading...\")\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded {file_name}.\")\n",
    "else:\n",
    "    print(f\"{file_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open(\"sentences.txt\", encoding=\"utf-8\").read().split(\"@@@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Encode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO we should update towards keras 3 soon\n",
    "# %pip install keras_nlp ### this is keras 3\n",
    "# %pip install tf-keras  ### this is pre keras 3\n",
    "%pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('intfloat/e5-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take a minute or two depending on CPU/GPU configuration\n",
    "sembeddings = model.encode([\"passage: \" + s for s in sentences], \n",
    "                           show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"sentences-e5.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take a minute or two depending on CPU/GPU configuration\n",
    "sembeddings2 = model2.encode(sentences, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"sentences-mpnet.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, text, corpus_embeddings, model, top=20):\n",
    "    # code query to restrict search space\n",
    "    question_embedding = model.encode(query)\n",
    "    \n",
    "    # Determine similarity (vectors are normalized)\n",
    "    sim = np.dot(corpus_embeddings, question_embedding)\n",
    "    \n",
    "    # Get most similar top by sorting\n",
    "    hits = [ { \"text\": text[i], \"score\": sim[i] } \n",
    "                     for i in sim.argsort()[::-1][0:top] ]\n",
    "    \n",
    "    # Return as dataframe\n",
    "    return pd.DataFrame(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"query: Is the climate crisis worse for poorer countries?\", \n",
    "       sentences, sembeddings, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"query: Is the war on Ukraine caused by Russia?\", \n",
    "       sentences, sembeddings, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"Is the climate crisis worse for poorer countries?\", \n",
    "       sentences, sembeddings2, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"Is the war on Ukraine caused by Russia?\", \n",
    "       sentences, sembeddings2, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
